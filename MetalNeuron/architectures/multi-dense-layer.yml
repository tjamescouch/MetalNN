name: "Multi Layer Dense NN"

layers:
  - type: Dense
    input_size: 256
    output_size: 256
    activation: relu
    initializer: he

  - type: LayerNormalization
    input_size: 256
    output_size: 256
    #learning_rate: 0.001

  - type: Dense
    input_size: 256
    output_size: 256
    activation: linear
    initializer: he

training:
  optimizer:
    type: adam
    learning_rate: 0.0001
    parameters:
      beta1: 0.9
      beta2: 0.999
      epsilon: 1e-8

  epochs: 2
  batch_size: 2

dataset:
  type: "function"

metadata:
  author: "James Couch"
  description: "Multi Layer Dense NN"
